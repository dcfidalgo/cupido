{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f960e06e-4123-4992-b028-e87939fee7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data import Data\n",
    "from pathlib import Path\n",
    "from train import CollateFn\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "import torch\n",
    "from llamore import SchemaPrompter, F1\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61101652-2e42-44e9-ac1e-17b16f6d06d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"./data/data.json\")\n",
    "data = Data.model_validate_json(data_path.read_text())\n",
    "examples = data.examples\n",
    "examples = [ex for ex in data.examples if ex.refs]\n",
    "train_data, valid_data = examples[:-200], examples[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8ff9e0-854c-4f48-bdfc-701816c12834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"numind/NuExtract-2.0-2B\",\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\",  # make sure to set padding to right for training\n",
    "    use_fast=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eff53f3-779b-47ce-a22e-2a45fb7a5ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collate = CollateFn(processor=processor, input_dir=\"/raven/u/dcfidalgo/projects/cupido/data/PLOS_1000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a7550c-00a8-42fb-8dfe-37c4ea82e544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"./finetune_lora/checkpoint-998\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    "    # use_cache=False, # for training,\n",
    "    #config=config,\n",
    "    #ignore_mismatched_sizes=is_mock_model,\n",
    "    # quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35652f3c-a0e3-4f82-8eea-4b5277283421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiled_model = torch.compile(model, mode=\"max-autotune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80493d49-ffd0-4865-a6c5-ae6697153728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "refs_model = SchemaPrompter().schema_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ffe2e14-d2e7-4ed8-a244-fafc402ae7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(example, max_new_tokens: int = 10000):\n",
    "    batch = collate([example])\n",
    "    batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "    \n",
    "    # Generate output\n",
    "    idx = (batch[\"labels\"][0] != -100).nonzero()[0][0].item()\n",
    "    batch[\"input_ids\"] = batch[\"input_ids\"][:, :idx + 1]\n",
    "    batch[\"attention_mask\"] = batch[\"attention_mask\"][:, :idx + 1]\n",
    "    with torch.inference_mode():\n",
    "        output = compiled_model.generate(**batch, max_new_tokens=max_new_tokens)\n",
    "    output = processor.tokenizer.decode(\n",
    "        output[0][idx:], skip_special_tokens=True\n",
    "    )  # Only keep the generated tokens\n",
    "    idx = output.find(\"{\")\n",
    "    try:\n",
    "        refs = refs_model.model_validate_json(output[idx:].strip())\n",
    "    except Exception:\n",
    "        predicted_references = []\n",
    "    else:\n",
    "        predicted_references = refs.references\n",
    "\n",
    "    # Get gold references\n",
    "    labels = batch[\"labels\"][0]\n",
    "    label = processor.tokenizer.decode(labels[labels != -100], skip_special_tokens=True)\n",
    "    idx = label.find(\"{\")\n",
    "    gold_references = refs_model.model_validate_json(label[idx:].strip())\n",
    "    \n",
    "    return predicted_references, gold_references.references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "991e581b-0796-4854-9bd9-b35c51bb1c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac90af2e57b41629f76bca9714cf11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_references, gold_references = [], []\n",
    "for example in track(valid_data[:10]):\n",
    "    preds, gold = predict(example, max_new_tokens=10000)\n",
    "    my_references.append(preds)\n",
    "    gold_references.append(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "920a55b0-e501-4245-a45d-e8b24f1f4de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd534c56d454dcfb34ea400b1e5327f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5935766743096721"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1().compute_macro_average(my_references, gold_references, num_processes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9917cfa-5381-4af7-a09d-6b67df58697d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\".env\", \"r\") as f:\n",
    "    GEMINI_API_KEY = f.readline().split(\"=\")[1].strip()[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f8c417c-5e33-44c7-80af-e9fe9f565643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "from llamore import GeminiExtractor\n",
    "\n",
    "\n",
    "extractor = GeminiExtractor(api_key=GEMINI_API_KEY)\n",
    "\n",
    "\n",
    "def predict_gemini(example):\n",
    "    pdfs_dir = Path(\"data/PLOS_1000/\")\n",
    "    pdf_path = pdfs_dir / example.file / f\"{example.file}.pdf\"\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    new_doc = pymupdf.open()\n",
    "    new_doc.insert_pdf(doc, from_page=example.page-1, to_page=example.page-1)\n",
    "    new_doc.save(\"test.pdf\")\n",
    "    \n",
    "    return extractor(pdf=\"test.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc336ce0-a092-442a-b948-9137e2599309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa55fba68084b12bc88ee4df78c7ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini_references = []\n",
    "\n",
    "for example in track(valid_data[:10]):\n",
    "    gemini_references.append(predict_gemini(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "745519f0-062c-43b7-afdd-6f0e85702f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b0851218bd4c3fbb330e6614c8f7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6698353357578595"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1().compute_macro_average(gemini_references, gold_references, num_processes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca1c21-e640-4b23-b067-31b28b6058e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupido",
   "language": "python",
   "name": "cupido"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
