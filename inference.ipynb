{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b5201a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f960e06e-4123-4992-b028-e87939fee7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data import Data, split, Example, export_page_as_pdf\n",
    "from pathlib import Path\n",
    "from train import CollateFn\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "import torch\n",
    "from llamore import SchemaPrompter, F1\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61101652-2e42-44e9-ac1e-17b16f6d06d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"./data/data.json\")\n",
    "pdfs_path = Path(\"./data/PLOS_1000/\")\n",
    "valid_path = Path(\"./data/pdfs_valid\")\n",
    "data = Data.model_validate_json(data_path.read_text())\n",
    "examples = data.examples\n",
    "examples = [ex for ex in data.examples if ex.refs]\n",
    "\n",
    "train_data, valid_data = split(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b7237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pages of the validation dataset as PDFs\n",
    "for i, example in enumerate(valid_data):\n",
    "    pdf_file = pdfs_path / example.file / f\"{example.file}.pdf\"\n",
    "    output = valid_path / f\"{i:03d}.pdf\"\n",
    "    export_page_as_pdf(pdf_file, example.page, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65dcee5",
   "metadata": {},
   "source": [
    "# Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8ff9e0-854c-4f48-bdfc-701816c12834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"numind/NuExtract-2.0-2B\",\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\",  # make sure to set padding to right for training\n",
    "    use_fast=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eff53f3-779b-47ce-a22e-2a45fb7a5ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collate = CollateFn(processor=processor, input_dir=\"/raven/u/dcfidalgo/projects/cupido/data/PLOS_1000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a7550c-00a8-42fb-8dfe-37c4ea82e544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"./finetune_lora/checkpoint-998\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    "    # use_cache=False, # for training,\n",
    "    #config=config,\n",
    "    #ignore_mismatched_sizes=is_mock_model,\n",
    "    # quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35652f3c-a0e3-4f82-8eea-4b5277283421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiled_model = torch.compile(model, mode=\"max-autotune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80493d49-ffd0-4865-a6c5-ae6697153728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "refs_model = SchemaPrompter().schema_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ffe2e14-d2e7-4ed8-a244-fafc402ae7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(example, max_new_tokens: int = 10000):\n",
    "    batch = collate([example])\n",
    "    batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "    \n",
    "    # Generate output\n",
    "    idx = (batch[\"labels\"][0] != -100).nonzero()[0][0].item()\n",
    "    batch[\"input_ids\"] = batch[\"input_ids\"][:, :idx + 1]\n",
    "    batch[\"attention_mask\"] = batch[\"attention_mask\"][:, :idx + 1]\n",
    "    with torch.inference_mode():\n",
    "        output = compiled_model.generate(**batch, max_new_tokens=max_new_tokens)\n",
    "    output = processor.tokenizer.decode(\n",
    "        output[0][idx:], skip_special_tokens=True\n",
    "    )  # Only keep the generated tokens\n",
    "    idx = output.find(\"{\")\n",
    "    try:\n",
    "        refs = refs_model.model_validate_json(output[idx:].strip())\n",
    "    except Exception:\n",
    "        predicted_references = []\n",
    "    else:\n",
    "        predicted_references = refs.references\n",
    "\n",
    "    # Get gold references\n",
    "    labels = batch[\"labels\"][0]\n",
    "    label = processor.tokenizer.decode(labels[labels != -100], skip_special_tokens=True)\n",
    "    idx = label.find(\"{\")\n",
    "    gold_references = refs_model.model_validate_json(label[idx:].strip())\n",
    "    \n",
    "    return predicted_references, gold_references.references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "991e581b-0796-4854-9bd9-b35c51bb1c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac90af2e57b41629f76bca9714cf11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_references, gold_references = [], []\n",
    "for example in track(valid_data[:10]):\n",
    "    preds, gold = predict(example, max_new_tokens=10000)\n",
    "    my_references.append(preds)\n",
    "    gold_references.append(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "920a55b0-e501-4245-a45d-e8b24f1f4de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd534c56d454dcfb34ea400b1e5327f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5935766743096721"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1().compute_macro_average(my_references, gold_references, num_processes=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupido",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
