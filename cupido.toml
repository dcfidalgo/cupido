dpi = 100
is_mock_model = true
use_flashattn = false

[sft_cfg]
output_dir="finetune_lora"  # Directory to save the model
num_train_epochs=2  # Number of training epochs
per_device_train_batch_size=1  # Batch size for training
per_device_eval_batch_size=1  # Batch size for evaluation
gradient_accumulation_steps=4  # Steps to accumulate gradients
learning_rate=1e-5  # Learning rate for training
lr_scheduler_type="constant"  # Type of learning rate scheduler
logging_steps=10  # Steps interval for logging
eval_steps=100  # Steps interval for evaluation
eval_strategy="steps"  # Strategy for evaluation
# save_strategy="steps",  # Strategy for saving the model
# save_steps=20,  # Steps interval for saving
bf16=true  # Use bfloat16 precision
max_grad_norm=0.3  # Maximum norm for gradient clipping
warmup_ratio=0.03  # Ratio of total steps for warmup
report_to="wandb"  # Reporting tool for tracking metrics
gradient_checkpointing=true  # Enable gradient checkpointing for memory efficiency
gradient_checkpointing_kwargs={use_reentrant = false}  # Options for gradient checkpointing
# eval_accumulation_steps=1,
dataloader_num_workers=4

[lora_cfg]
lora_alpha=16  # Scaling factor for LoRA
lora_dropout=0.05  # Dropout rate for LoRA layers
r=8  # Rank of the low-rank decomposition
bias="none"  # Bias handling in LoRA layers
target_modules=["q_proj", "v_proj"]  # Target modules for LoRA
task_type="CAUSAL_LM"  # Task type for the model